const { HNSWLib } = require("@langchain/community/vectorstores/hnswlib");
const { OpenAIEmbeddings, ChatOpenAI } = require("@langchain/openai");
const { TextLoader } = require("langchain/document_loaders/fs/text");
const { RecursiveCharacterTextSplitter } = require("langchain/text_splitter");
const { formatDocumentsAsString } = require("langchain/util/document");
const {
  RunnablePassthrough,
  RunnableSequence,
} = require("@langchain/core/runnables");
const { StringOutputParser } = require("@langchain/core/output_parsers");
const { PromptTemplate } = require("@langchain/core/prompts");
const readlineSync = require("readline-sync");
require("dotenv").config();

// Initialize the LLM to use to answer the question.
const model = new ChatOpenAI({});
const prompt =
  PromptTemplate.fromTemplate(`RÃ©pondre aux questions de l'utilistateur uniquement sur le sujet:
{context}. Si vous ne savez pas la rÃ©ponse, demander Ã  contacter le service client au tÃ©lÃ©phone ou par email.
Question: {question}`);

// Fragmenter les documents en plusieurs morceaux
const splitDocuments = async () => {
  const loader = new TextLoader("./docs/faq_fr.txt");
  const docs = await loader.load();
  const textSplitter = new RecursiveCharacterTextSplitter({
    chunkSize: 100,
    chunkOverlap: 0,
  });
  
  const chunks = await textSplitter.splitDocuments(docs);
  console.log(`Nombre de documents : ${docs.length}, nombre de chunks : ${chunks.length}`);
  return chunks;
 }

// CrÃ©er une base de donnÃ©es vectorielle
const createVectorStore = async (docs) => { 
  // console.log(docs)
  docsContents = docs.map(doc => doc.pageContent)
  const vectorStore = await HNSWLib.fromTexts(
    docsContents,
    [{ id: 1 }],
    new OpenAIEmbeddings()
  );
  const retriever = vectorStore.asRetriever();
  return retriever
}

// CrÃ©er la chaÃ®ne de composants pour gÃ©nÃ©rer du contenu augmentÃ©
const createChain = async (query) => {}

// ExÃ©cuter la chaÃ®ne de composants pour gÃ©nÃ©rer du contenu augmentÃ©
const generateResponse = async (query) => {
  return query
};

function getInput(promptMessage) {
  return readlineSync.question(promptMessage, {
    hideEchoBack: false, // The typed characters won't be displayed if set to true
  });
}

async function main() {
  console.log("\x1b[34m \n\n----------------------------------");
  console.log("          CHAT WITH AI ğŸ¤–   ");
  console.log("----------------------------------\n \x1b[0m");
  console.log("\x1b[34mTaper 'x' pour quitter l'application\n  \x1b[0m");
  runConversation();
}

const test = async () => {
  const chunks = await splitDocuments();
  await createVectorStore(chunks);
  // await createChain();
  // await generateResponse();
}

test()


async function runConversation() {
  while (true) {
    const input = getInput("You: ");

    if (input === "x") {
      console.log("\x1b[34mBot: Bye! ğŸ‘‹ğŸ½");
      process.exit();
    }

    if (!!input) {
      try {
        const response = await generateResponse(input);
        console.log("\x1b[32mBot: " + response + "\x1b[0m");
      } catch (error) {
        console.error(error);
      }
    }
  }
}
// main()

